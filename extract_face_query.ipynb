{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlO9znrQfl+D08WkbRrrgi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9f_Yl4WX_v9Z"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","import pickle\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"YcyKnbs4_03R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnxruntime"],"metadata":{"id":"aX4zuaju_4Yu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install insightface"],"metadata":{"id":"e6pcxxo2_6v1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import insightface\n","from insightface.app import FaceAnalysis\n","from insightface.data import get_image as ins_get_image"],"metadata":{"id":"jw2GzfF5_9Ov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ins_detector = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n","ins_detector.prepare(ctx_id=0, det_size=(640, 640))"],"metadata":{"id":"oMbrrmRI_-xt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Các hàm liên quan insightface"],"metadata":{"id":"NY-qbz2fA79w"}},{"cell_type":"code","source":["def get_meta_data(faces):\n","  data = []\n","  attributes = ['bbox', 'kps', 'det_score']\n","  for index in range(len(faces)):\n","    meta_data = {}\n","    for attr in attributes:\n","      meta_data[attr] = faces[index][attr]\n","    data.append(meta_data)\n","  return data"],"metadata":{"id":"YSuRR2S9BMnJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bbox_insightface(faces):\n","  res_faces = []\n","  for index in range(len(faces)):\n","    res = tuple(faces[index]['bbox'])\n","    res = tuple(map(round, res))\n","    res = (max(res[1],0), max(res[3],0), max(res[0], 0), max(res[2],0))\n","    res_faces.append(res)\n","  return res_faces"],"metadata":{"id":"P7Up5qjZBNDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_face_ins(img_path):\n","  img_path = \"\".join(img_path.split(\".\")[:-1])\n","\n","  img = ins_get_image(img_path)\n","  faces = ins_detector.get(img)\n","\n","  #meta_data = get_meta_data(faces)\n","\n","  res_faces = get_bbox_insightface(faces)\n","  return res_faces"],"metadata":{"id":"DdGiJwmXBQWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_img(filepath, mode=\"RGB\"):\n","    \"\"\"\n","    Function to read image from file and convert it to RGB by default, or leaves BGR.\n","    Input: file path.\n","    Output: image as numpy array.\n","    \"\"\"\n","    img = cv2.imread(filepath)\n","    if mode == \"RGB\":\n","        # Convert to RGB\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    return img"],"metadata":{"id":"Lmv4AruYBTZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_roi(image, coordinates):\n","    \"\"\"\n","    Function to extract region of interest (roi) from image using coordinates.\n","    Input image: image as numpy array to extract from.\n","    Input coordinates: coordinates of roi in form of tuple (top, bottom, left, right)\n","    \"\"\"\n","    # Check negative coordinates    \n","    top = coordinates[0] if coordinates[0] - 5 < 0 else coordinates[0] - 5 \n","    bottom = coordinates[1] + 5\n","    left = coordinates[2] if coordinates[2] - 5 < 0 else coordinates[2] - 5\n","    right = coordinates[3] + 5\n","    # roi = image[coordinates[0]-5:coordinates[1]+5, coordinates[2]-5:coordinates[3]+5]\n","    roi = image[top:bottom,left:right]\n","    return roi"],"metadata":{"id":"9VPgfEx3BVFp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# facenet-pytorch"],"metadata":{"id":"bth4dXyqBYT7"}},{"cell_type":"code","source":["!pip install facenet-pytorch\n","from facenet_pytorch import MTCNN \n","model_MTCNN = MTCNN(device='cuda')"],"metadata":{"id":"agVVWxFxB-fD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_face_by_facenet_pytorch_mtcnn(model, image_path):  \n","  #detect_faces_single_image(path_imgg)\n","  img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n","  rows = img.shape[0]\n","  cols = img.shape[1]\n","  boxes, probs = model.detect(img, landmarks=False)\n","  if boxes is None:\n","    return None\n","    #print('No face !')\n","  else:\n","    for box, prob in zip(boxes, probs):\n","      x1, y1, x2, y2 = [int(x) for x in box]\n","      if x1<0: x1=0\n","      if y1<0: y1=0\n","      if x2<0: x2=0\n","      if y2<0: y2=0  \n","      #print(f\"x1={x1}, x2={x2}, y1={y1}, y2={y2}\")\n","      #face = cv2.cvtColor(img[y1:y2, x1:x2],cv2.COLOR_RGB2BGR)\n","      #cv2_imshow(face)\n","\n","      if x1 > 4: x1 = x1-5\n","      else: x1 = 0\n","      if x2 < cols: x2 = x2 + min(5, cols - x2)\n","        \n","      if y1>4: y1=y1-5\n","      else: y1= 0\n","      if y2 < rows: y2 = y2 + min(5, rows - y2)      \n","      #print(f\"x1={x1}, x2={x2}, y1={y1}, y2={y2}\")\n","      face = cv2.cvtColor(img[y1:y2, x1:x2],cv2.COLOR_RGB2BGR)\n","      return face\n","      #cv2_imshow(face)"],"metadata":{"id":"RwvuUejdCBsV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Extract face cho query"],"metadata":{"id":"mnIYLEhFCH95"}},{"cell_type":"code","source":["root_dir = \"/content/drive/MyDrive/KLTN2022_ThanhHa/dataset/TRECVID_MSUM_2022/\"\n","query_dir = os.path.join(root_dir,\"query\")\n","faces_query_dir = os.path.join(root_dir,\"faces_query\")\n","features_query_dir = os.path.join(root_dir,\"features_query/insightface\")\n","\n","list_movies = sorted(os.listdir(query_dir))\n","for movie_name in list_movies:\n","  path_to_movie = os.path.join(query_dir,movie_name)\n","  path_to_movie_faces_query = os.path.join(faces_query_dir,movie_name)\n","  path_to_features_query = os.path.join(features_query_dir,movie_name)\n","\n","  if not os.path.isdir(path_to_movie_faces_query):\n","    os.makedirs(path_to_movie_faces_query)\n","  if not os.path.isdir(path_to_features_query):\n","    os.makedirs(path_to_features_query)\n","  \n","\n","  list_charactors = sorted(os.listdir(path_to_movie))\n","  for char_name in list_charactors:\n","    path_to_movie_char = os.path.join(path_to_movie,char_name)\n","    path_to_movie_faces_query_char = os.path.join(path_to_movie_faces_query,char_name)\n","    path_to_features_query_char = os.path.join(path_to_features_query,char_name)\n","    \n","    if not os.path.isdir(path_to_movie_faces_query_char):\n","      os.makedirs(path_to_movie_faces_query_char)\n","    if not os.path.isdir(path_to_features_query_char):\n","      os.makedirs(path_to_features_query_char)\n","      \n","\n","    list_img_query = sorted(os.listdir(path_to_movie_char))\n","    for img_query in list_img_query:\n","      path_to_img_query = os.path.join(path_to_movie_char,img_query)\n","      #img0 = read_img(path_to_img_query)\n","      #cv2_imshow(img0)\n","      # Thưc hiện extract face bằng insightface\n","      path_to_img_query_by_insightface = \"\".join(path_to_img_query.split(\".\")[:-1])\n","      img = ins_get_image(path_to_img_query_by_insightface)\n","      faces = ins_detector.get(img)\n","      if len(faces)>1:\n","        print(f'insightface: detect {len(faces)} face !', img_query)\n","      else:\n","        if faces is None or len(faces)<1 :\n","          print('insightface: can not detect face !', img_query)\n","          print('Detecting by MTCNN')\n","          img_by_MTCNN = cv2.cvtColor(cv2.imread(path_to_img_query), cv2.COLOR_BGR2RGB)\n","          rows = img_by_MTCNN.shape[0]\n","          cols = img_by_MTCNN.shape[1]\n","\n","          boxes, probs, landmarks = model_MTCNN.detect(img_by_MTCNN, landmarks=True)\n","          if boxes is None or len(boxes)<1 :\n","            print('MTCNN: can not detect face !', img_query)\n","          else:\n","            bbox=boxes[0]\n","            \n","            if bbox[0]<0: bbox[0] = 0\n","            if bbox[1]<0: bbox[1] = 0\n","            if bbox[2]<0: bbox[2] = 0\n","            if bbox[3]<0: bbox[3] = 0\n","            #x1\n","            if bbox[0]>4: bbox[0] = bbox[0]-5\n","            else: bbox[0] = 0\n","            #x2            \n","            if bbox[2] < cols: bbox[2] = bbox[2] + min(5, cols - bbox[2])\n","            #y1\n","            if bbox[1]>4: bbox[1] = bbox[1]-5\n","            else: bbox[1] = 0\n","            #y2            \n","            if bbox[3] < rows: bbox[3] = bbox[3] + min(5, rows - bbox[3])\n","            #bbox=boxes[0]\n","            #print(bbox)\n","            img_face = cv2.cvtColor(img_by_MTCNN[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])],cv2.COLOR_RGB2BGR)\n","            face = Face(bbox=bbox, kps=landmarks[0], det_score=probs[0])\n","            embedding = model_recognition.get(img_by_MTCNN, face)\n","        else:\n","          res_faces = get_bbox_insightface(faces)\n","          face = faces[0]\n","          #print(face)\n","          img_face = get_roi(img,res_faces[0])\n","          #img_face = cv2.cvtColor(img_face,cv2.COLOR_RGB2BGR)\n","          embedding = face['embedding']\n","        \n","        framename  = img_query.split(\".\")[0]\n","        filename_face = f\"{framename}.jpg\"\n","\n","        path_to_img_query_face =  os.path.join(path_to_movie_faces_query_char,filename_face)\n","        \n","        cv2_imshow(img_face)\n","        \n","        cv2.imwrite(path_to_img_query_face, img_face)\n","        \n","        filename_out = f\"{framename}.pickle\"        \n","        embedding_file = os.path.join(path_to_features_query_char,filename_out)\n","        with open(embedding_file, 'wb') as handle:\n","          pickle.dump(embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        print(filename_out, \": \", len(embedding))\n","\n","print(\"Da hoan thanh viec extract face\")"],"metadata":{"id":"feF41o6SCEWD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Deepface Rút trích đăch trưng cho query"],"metadata":{"id":"Sp9MObx9COxf"}},{"cell_type":"code","source":["!pip install deepface"],"metadata":{"id":"xbqqxV6nCL8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from deepface import DeepFace"],"metadata":{"id":"ABaIDQY3CLyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = \"Facenet512\"\n","#model_name = \"ArcFace\""],"metadata":{"id":"LTeaOVgaCU6x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root_dir = \"/content/drive/MyDrive/KLTN2022_ThanhHa/dataset/TRECVID_MSUM_2022/\"\n","faces_query_dir = os.path.join(root_dir,\"faces_query\")\n","features_query_dir = os.path.join(root_dir,\"features_query/deepface/\", model_name)\n","if not os.path.isdir(features_query_dir):\n","    os.makedirs(features_query_dir)\n","\n","query_dir = os.path.join(root_dir,\"query\")\n","list_movies = sorted(os.listdir(query_dir))#\n","for movie_name in list_movies:\n","  path_to_movie = os.path.join(query_dir,movie_name)\n","  path_to_movie_faces_query = os.path.join(faces_query_dir,movie_name)\n","  path_to_features_query = os.path.join(features_query_dir,movie_name)\n","\n","  if not os.path.isdir(path_to_movie_faces_query):\n","    print (f'{path_to_movie_faces_query} chưa có')\n","    continue    \n","  if not os.path.isdir(path_to_features_query):\n","    os.makedirs(path_to_features_query)\n","  \n","\n","  list_charactors = sorted(os.listdir(path_to_movie))\n","  for char_name in list_charactors:\n","    path_to_movie_char = os.path.join(path_to_movie,char_name)\n","    path_to_movie_faces_query_char = os.path.join(path_to_movie_faces_query,char_name)\n","    path_to_features_query_char = os.path.join(path_to_features_query,char_name)\n","    \n","    if not os.path.isdir(path_to_movie_faces_query_char):\n","      os.makedirs(path_to_movie_faces_query_char)\n","    if not os.path.isdir(path_to_features_query_char):\n","      os.makedirs(path_to_features_query_char)     \n","\n","    list_img_query = sorted(os.listdir(path_to_movie_char))\n","    for img_query in list_img_query:\n","      framename  = img_query.split(\".\")[0]\n","      filename_out = f\"{framename}.jpg\"          \n","      img_path_face = os.path.join(path_to_movie_faces_query_char,filename_out)\n","      if os.path.exists(img_path_face):\n","        img = cv2.imread(img_path_face)\n","        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        embedding = DeepFace.represent(img_path = img_path_face, model_name = model_name , enforce_detection=False)\n","        filename_out = f\"{framename}.pickle\"\n","#        embedding = embedding.reshape(-1, 1)\n","        embedding_file = os.path.join(path_to_features_query_char,filename_out)\n","        with open(embedding_file, 'wb') as handle:\n","          pickle.dump(embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        cv2_imshow(img)\n","        print(embedding_file, \": \", len(embedding))\n","\n","print(\"Da hoan thanh viec extract feature\")"],"metadata":{"id":"8HiirDjDCWbd"},"execution_count":null,"outputs":[]}]}